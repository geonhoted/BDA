{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\장건호\\Desktop\\BDA\\taiwanese+bankruptcy+prediction\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs_forward 선택된 특성\n",
    "selected_1 = [' ROA(C) before interest and depreciation before interest', ' ROA(B) before interest and depreciation after tax', ' Operating Gross Margin', ' Realized Sales Gross Margin', ' Operating Profit Rate', ' Pre-tax net Interest Rate', ' After-tax net Interest Rate', ' Non-industry income and expenditure/revenue', ' Continuous interest rate (after tax)', ' Cash flow rate', ' Net Value Per Share (B)', ' Net Value Per Share (A)', ' Net Value Per Share (C)', ' Persistent EPS in the Last Four Seasons', ' Cash Flow Per Share', ' Revenue Per Share (Yuan ¥)', ' Operating Profit Per Share (Yuan ¥)', ' Per Share Net profit before tax (Yuan ¥)', ' Realized Sales Gross Profit Growth Rate', ' Operating Profit Growth Rate', ' Borrowing dependency', ' Long-term Liability to Current Assets', ' Equity to Long-term Liability']\n",
    "X1 = data[selected_1]\n",
    "#sfs_backward 선택된 특성\n",
    "selected_2 = [' ROA(C) before interest and depreciation before interest', ' ROA(A) before interest and % after tax']\n",
    "X2 = data[selected_2]\n",
    "#sfs_stepwise 선택된 특성\n",
    "selected_3 = [' ROA(C) before interest and depreciation before interest', ' ROA(A) before interest and % after tax', ' ROA(B) before interest and depreciation after tax', ' Operating Gross Margin', ' Realized Sales Gross Margin', ' Operating Profit Rate', ' Pre-tax net Interest Rate', ' After-tax net Interest Rate', ' Non-industry income and expenditure/revenue', ' Continuous interest rate (after tax)', ' Cash flow rate', ' Tax rate (A)', ' Net Value Per Share (B)', ' Net Value Per Share (A)', ' Net Value Per Share (C)', ' Persistent EPS in the Last Four Seasons', ' Cash Flow Per Share', ' Revenue Per Share (Yuan ¥)', ' Operating Profit Per Share (Yuan ¥)', ' Per Share Net profit before tax (Yuan ¥)', ' Realized Sales Gross Profit Growth Rate', ' Operating Profit Growth Rate', ' After-tax Net Profit Growth Rate', ' Regular Net Profit Growth Rate', ' Continuous Net Profit Growth Rate', ' Total Asset Return Growth Rate Ratio', ' Cash Reinvestment %', ' Current Ratio', ' Interest Expense Ratio', ' Debt ratio %', ' Net worth/Assets', ' Long-term fund suitability ratio (A)', ' Borrowing dependency', ' Contingent liabilities/Net worth', ' Operating profit/Paid-in capital', ' Net profit before tax/Paid-in capital', ' Inventory and accounts receivable/Net value', ' Total Asset Turnover', ' Net Worth Turnover Rate (times)', ' Operating profit per person', ' Working Capital to Total Assets', ' Quick Assets/Total Assets', ' Current Assets/Total Assets', ' Cash/Total Assets', ' Quick Assets/Current Liability', ' Current Liability to Assets', ' Operating Funds to Liability', ' Inventory/Working Capital', ' Current Liabilities/Liability', ' Working Capital/Equity', ' Current Liabilities/Equity', ' Retained Earnings to Total Assets', ' Total income/Total expense', ' Total expense/Assets', ' Working capitcal Turnover Rate', ' Cash Flow to Sales', ' Current Liability to Liability', ' Current Liability to Equity', ' Equity to Long-term Liability', ' Cash Flow to Total Assets', ' Cash Flow to Liability', ' CFO to Assets', ' Cash Flow to Equity', ' Current Liability to Current Assets', ' Net Income to Total Assets', ' No-credit Interval', ' Gross Profit to Sales', \" Net Income to Stockholder's Equity\", ' Degree of Financial Leverage (DFL)', ' Interest Coverage Ratio (Interest expense to EBIT)', ' Net Income Flag', ' Equity to Liability']\n",
    "X3 = data[selected_3]\n",
    "#RFE 선택된 특성\n",
    "selected_4 = [' Revenue Per Share (Yuan ¥)', ' Accounts Receivable Turnover',\n",
    "       ' Average Collection Days', ' Allocation rate per person',\n",
    "       ' Fixed Assets to Assets']\n",
    "X4 = data[selected_4]\n",
    "#RFECV 선택된 특성\n",
    "selected_5 = [' ROA(C) before interest and depreciation before interest',\n",
    "       ' Non-industry income and expenditure/revenue',\n",
    "       ' Continuous interest rate (after tax)',\n",
    "       ' Interest-bearing debt interest rate', ' Net Value Per Share (C)',\n",
    "       ' Persistent EPS in the Last Four Seasons',\n",
    "       ' Per Share Net profit before tax (Yuan ¥)', ' Net Value Growth Rate',\n",
    "       ' Quick Ratio', ' Interest Expense Ratio',\n",
    "       ' Total debt/Total net worth', ' Net worth/Assets',\n",
    "       ' Borrowing dependency', ' Net profit before tax/Paid-in capital',\n",
    "       ' Accounts Receivable Turnover', ' Cash/Total Assets',\n",
    "       ' Inventory/Working Capital', ' Working Capital/Equity',\n",
    "       ' Net Income to Total Assets', ' Net Income to Stockholder\\'s Equity',\n",
    "       ' Degree of Financial Leverage (DFL)',\n",
    "       ' Interest Coverage Ratio (Interest expense to EBIT)']\n",
    "X5 = data[selected_5]\n",
    "\n",
    "y = data['Bankrupt?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model Feature Selection Method  Accuracy  Precision    Recall  \\\n",
      "0  LogisticRegression               selected_1  0.961877   0.000000  0.000000   \n",
      "1  LogisticRegression               selected_2  0.961877   0.500000  0.025641   \n",
      "2  LogisticRegression               selected_3  0.964321   0.777778  0.089744   \n",
      "3  LogisticRegression               selected_4  0.958456   0.000000  0.000000   \n",
      "4  LogisticRegression               selected_5  0.961877   0.000000  0.000000   \n",
      "\n",
      "        F1                                  Selected Features  \n",
      "0  0.00000  [ ROA(C) before interest and depreciation befo...  \n",
      "1  0.04878  [ ROA(C) before interest and depreciation befo...  \n",
      "2  0.16092  [ ROA(C) before interest and depreciation befo...  \n",
      "3  0.00000  [ Revenue Per Share (Yuan ¥),  Accounts Receiv...  \n",
      "4  0.00000  [ ROA(C) before interest and depreciation befo...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=200),\n",
    "    #'RandomForestClassifier': RandomForestClassifier(),\n",
    "    #'SVC': SVC(kernel='linear')\n",
    "}\n",
    "\n",
    "# 평가 지표를 계산하는 함수\n",
    "def evaluate_model(X, y, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 각 피처 선택 방법과 모델에 대한 평가 지표 계산\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for i, (X, selected_features) in enumerate(zip([X1, X2, X3, X4, X5], \n",
    "                                                   [selected_1, selected_2, selected_3, selected_4, selected_5]), 1):\n",
    "        accuracy, precision, recall, f1 = evaluate_model(X, y, model)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Feature Selection Method': f'selected_{i}',\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'Selected Features': selected_features\n",
    "        })\n",
    "\n",
    "# 결과 출력\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model     Dataset  Train Accuracy  Train Precision  \\\n",
      "0  LogisticRegression  selected_1        0.967919         0.000000   \n",
      "1  LogisticRegression  selected_2        0.967736         0.461538   \n",
      "2  LogisticRegression  selected_3        0.970119         0.730769   \n",
      "3  LogisticRegression  selected_4        0.222548         0.031351   \n",
      "4  LogisticRegression  selected_5        0.967186         0.166667   \n",
      "\n",
      "   Train Recall  Train F1  Test Accuracy  Test Precision  Test Recall  \\\n",
      "0      0.000000  0.000000       0.967009        0.000000     0.000000   \n",
      "1      0.034286  0.063830       0.967009        0.500000     0.044444   \n",
      "2      0.108571  0.189055       0.968475        0.625000     0.111111   \n",
      "3      0.777143  0.060270       0.207478        0.035009     0.866667   \n",
      "4      0.005714  0.011050       0.966276        0.000000     0.000000   \n",
      "\n",
      "    Test F1                                  Selected Features  \n",
      "0  0.000000   ROA(C) before interest and depreciation befor...  \n",
      "1  0.081633   ROA(C) before interest and depreciation befor...  \n",
      "2  0.188679   ROA(C) before interest and depreciation befor...  \n",
      "3  0.067299   Revenue Per Share (Yuan ¥),  Accounts Receiva...  \n",
      "4  0.000000   ROA(C) before interest and depreciation befor...  \n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=200),\n",
    "    # 'RandomForestClassifier': RandomForestClassifier(),\n",
    "    # 'SVC': SVC(kernel='linear')\n",
    "}\n",
    "\n",
    "# 평가 지표를 계산하는 함수\n",
    "def evaluate_model(X, y, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    train_metrics = {\n",
    "        'Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "        'Precision': precision_score(y_train, y_pred_train, zero_division=0),\n",
    "        'Recall': recall_score(y_train, y_pred_train, zero_division=0),\n",
    "        'F1': f1_score(y_train, y_pred_train, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    test_metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "        'Precision': precision_score(y_test, y_pred_test, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred_test, zero_division=0),\n",
    "        'F1': f1_score(y_test, y_pred_test, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    return train_metrics, test_metrics\n",
    "\n",
    "# 각 피처 선택 방법과 모델에 대한 평가 지표 계산\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for i, (X, selected_features) in enumerate(zip([X1, X2, X3, X4, X5], \n",
    "                                                   [selected_1, selected_2, selected_3, selected_4, selected_5]), 1):\n",
    "        train_metrics, test_metrics = evaluate_model(X, y, model)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Dataset': f'selected_{i}',\n",
    "            'Train Accuracy': train_metrics['Accuracy'],\n",
    "            'Train Precision': train_metrics['Precision'],\n",
    "            'Train Recall': train_metrics['Recall'],\n",
    "            'Train F1': train_metrics['F1'],\n",
    "            'Test Accuracy': test_metrics['Accuracy'],\n",
    "            'Test Precision': test_metrics['Precision'],\n",
    "            'Test Recall': test_metrics['Recall'],\n",
    "            'Test F1': test_metrics['F1'],\n",
    "            'Selected Features': ', '.join(selected_features)\n",
    "        })\n",
    "\n",
    "# 결과 출력\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ROA(C) before interest and depreciation before interest',\n",
       " ' Non-industry income and expenditure/revenue',\n",
       " ' Continuous interest rate (after tax)',\n",
       " ' Net Value Per Share (C)',\n",
       " ' Persistent EPS in the Last Four Seasons',\n",
       " ' Revenue Per Share (Yuan ¥)',\n",
       " ' Per Share Net profit before tax (Yuan ¥)',\n",
       " ' Borrowing dependency']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "total_selected = selected_1 + selected_2 + selected_3 + selected_4 + selected_5\n",
    "total_number = Counter(total_selected)\n",
    "selected = [elem for elem, count in total_number.items() if count > 2]\n",
    "\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = [ ' Debt ratio %', ' Current Liability to Assets',\n",
    "       ' Borrowing dependency', ' Current Liability to Current Assets',\n",
    "       ' Liability to Equity', ' Current Liabilities/Equity',\n",
    "       ' Current Liability to Equity', ' Liability-Assets Flag',\n",
    "       ' Total expense/Assets', ' Equity to Long-term Liability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
      "                                              0.0/258.0 kB ? eta -:--:--\n",
      "     -----                                 41.0/258.0 kB 960.0 kB/s eta 0:00:01\n",
      "     ------------------                     122.9/258.0 kB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------         204.8/258.0 kB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 258.0/258.0 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.2 imblearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Support Vector Classifier (SVC) 모델\n",
    "svc_model = SVC()\n",
    "svc_model = make_pipeline(StandardScaler(), SVC(class_weight='balanced'))\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "print(\"SVC Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"SVC recall:\\n\", recall_score(y_test, y_pred_svc))\n",
    "print(\"SVC f1:\\n\", f1_score(y_test,y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Train Accuracy  Train Precision  Train Recall  \\\n",
      "0  RandomForestClassifier        0.874597          0.86972      0.880296   \n",
      "\n",
      "   Train F1  Test Accuracy  Test Precision  Test Recall   Test F1  \\\n",
      "0  0.874976       0.866667        0.868816     0.867515  0.868165   \n",
      "\n",
      "                                   Selected Features  \n",
      "0  ROA(C) before interest and depreciation before...  \n"
     ]
    }
   ],
   "source": [
    "X = data[corr]\n",
    "y = data['Bankrupt?']\n",
    "\n",
    "bankrupt_count = data['Bankrupt?'].value_counts()\n",
    "max_count = bankrupt_count.max()\n",
    "smote = SMOTE(sampling_strategy={i: max_count for i in bankrupt_count.index})\n",
    "\n",
    "X, y = smote.fit_resample(X, y)\n",
    "balanced_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Check the balanced count for each attack category\n",
    "balanced_Bankrupt_counts = balanced_data['Bankrupt?'].value_counts()\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    #'LogisticRegression': LogisticRegression(max_iter=200)\n",
    "    'RandomForestClassifier': RandomForestClassifier(n_estimators=1000,  # 기본 트리의 수\n",
    "        max_depth=5,  # 트리의 최대 깊이 제한\n",
    "        min_samples_split=2,  # 노드를 분할하는 데 필요한 최소 샘플 수\n",
    "        min_samples_leaf=1,  # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "        max_features='sqrt',  # 각 분할에 사용할 피처의 최대 수\n",
    "        random_state=111  # 결과 재현성을 위한 랜덤 시드\n",
    "    )\n",
    "    #'SVC': SVC(StandardScaler(), SVC(class_weight='balanced'))\n",
    "}\n",
    "\n",
    "# 평가 지표를 계산하는 함수\n",
    "def evaluate_model(X, y, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    train_metrics = {\n",
    "        'Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "        'Precision': precision_score(y_train, y_pred_train, zero_division=0),\n",
    "        'Recall': recall_score(y_train, y_pred_train, zero_division=0),\n",
    "        'F1': f1_score(y_train, y_pred_train, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    test_metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "        'Precision': precision_score(y_test, y_pred_test, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred_test, zero_division=0),\n",
    "        'F1': f1_score(y_test, y_pred_test, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    return train_metrics, test_metrics\n",
    "\n",
    "# 모델 평가\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    train_metrics, test_metrics = evaluate_model(X, y, model)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy': train_metrics['Accuracy'],\n",
    "        'Train Precision': train_metrics['Precision'],\n",
    "        'Train Recall': train_metrics['Recall'],\n",
    "        'Train F1': train_metrics['F1'],\n",
    "        'Test Accuracy': test_metrics['Accuracy'],\n",
    "        'Test Precision': test_metrics['Precision'],\n",
    "        'Test Recall': test_metrics['Recall'],\n",
    "        'Test F1': test_metrics['F1'],\n",
    "        'Selected Features': ', '.join(selected_features)\n",
    "    })\n",
    "\n",
    "# 결과 출력\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics: {'Accuracy': 0.8612282309807516, 'Precision': 0.1759465478841871, 'Recall': 0.9028571428571428, 'F1': 0.29450139794967384}\n",
      "Test Metrics: {'Accuracy': 0.8680351906158358, 'Precision': 0.18009478672985782, 'Recall': 0.8444444444444444, 'F1': 0.29687500000000006}\n"
     ]
    }
   ],
   "source": [
    "y = data['Bankrupt?']\n",
    "X = data[selected]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n",
    "\n",
    "# Pipeline 정의\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # StandardScaler를 사용하여 데이터 표준화\n",
    "    ('svc', SVC(class_weight='balanced'))  # SVC 모델을 사용\n",
    "])\n",
    "\n",
    "# 모델 학습\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# 평가 지표 계산\n",
    "train_metrics = {\n",
    "    'Accuracy': accuracy_score(y_train, y_pred_train),\n",
    "    'Precision': precision_score(y_train, y_pred_train, zero_division=0),\n",
    "    'Recall': recall_score(y_train, y_pred_train, zero_division=0),\n",
    "    'F1': f1_score(y_train, y_pred_train, zero_division=0)\n",
    "}\n",
    "\n",
    "test_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "    'Precision': precision_score(y_test, y_pred_test, zero_division=0),\n",
    "    'Recall': recall_score(y_test, y_pred_test, zero_division=0),\n",
    "    'F1': f1_score(y_test, y_pred_test, zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"Train Metrics:\", train_metrics)\n",
    "print(\"Test Metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 방법으로 피처를 선정하고, 모델 사용도 다양하게 진행해보았다.\n",
    "하지만 피처선정과, 모델 선택과 관계없이 전체적인 평가지표가 고르게 나오는 경우가 없어, 데이터 전처리가 필요하다고 판단하였고, Smote Sampling을 통해서 뷸균형 데이터를 완화해서 랜덤포레스트의 파라미터를 변경해가며 학습을 진행시켰더니                     \n",
    "\n",
    "Model                       Train Accuracy   Train Precision  Train Recall \n",
    "RandomForestClassifier        0.874597          0.86972         0.880296   \n",
    "\n",
    "Train F1  Test Accuracy  Test Precision  Test Recall    Test F1  \n",
    "0.874976    0.866667        0.868816     0.867515       0.868165 \n",
    "\n",
    "와 같은 결과를 얻을 수 있었습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
